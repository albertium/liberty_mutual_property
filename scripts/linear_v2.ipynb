{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "00, base, 0.33197\n",
    "01, cap .99, 0.33311\n",
    "02, cap .95, 0.33367\n",
    "03, cap .95 + AB, 0.34576, 0.335084\n",
    "04, cap .99 + AB + count, 0.34279\n",
    "05, cap .95 + AB + count, 0.34279, 0.331620\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "categorical only + various estimator\n",
    "numerical only + various estimator\n",
    "variable selection (xgb, RF) + various estimator\n",
    "numerical as categorical\n",
    "second order features\n",
    "standardize kfold transformer\n",
    "numerical as categorical + 2nd order + linear\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import vw_utils as vw\n",
    "import gini\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cap: 12.0\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "cap = train.Hazard.quantile(0.95)\n",
    "print('Cap:', cap)\n",
    "\n",
    "train['Hazard_cap'] = np.minimum(train.Hazard, cap)\n",
    "\n",
    "data = pd.concat([train, test], axis=0).reset_index()\n",
    "train_set = np.hstack([np.ones(train.shape[0]), np.zeros(test.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------- Feature Start -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start\n",
    "categorical = ['T1_V' + str(i) for i in list(range(4, 10)) + [11, 12, 15, 16, 17]] + \\\n",
    "                ['T2_V' + str(i) for i in [3, 5, 11, 12, 13]]\n",
    "\n",
    "numerical = set(train.columns).difference(categorical + ['Hazard', 'Hazard_cap', 'Id'])\n",
    "numerical = list(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101999, 32)"
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "\n",
    "SS = StandardScaler()\n",
    "feat_raw = data[numerical].applymap(float)\n",
    "feat_raw[numerical] = SS.fit_transform(feat_raw[numerical])\n",
    "\n",
    "\n",
    "toDrop = re.sub('[ ]+', '_', data[categorical].ix[0, :].to_string()).split('\\n')\n",
    "# feat_raw_cat = pd.get_dummies(data[categorical]).drop(toDrop, axis=1)\n",
    "\n",
    "feat_raw = pd.concat([feat_raw, data[categorical]], axis=1)\n",
    "feat_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 140 ms, total: 2.04 s\n",
      "Wall time: 2.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albertium/anaconda3/lib/python3.4/site-packages/sklearn/utils/validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# count features\n",
    "from wrappers import generatePrimes, calPowerCount\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feat_count = pd.concat([calPowerCount(data[categorical], 1), \n",
    "                        calPowerCount(data[categorical], 2)], axis=1)\n",
    "\n",
    "cols = feat_count.columns\n",
    "feat_count = pd.DataFrame(StandardScaler().fit_transform(feat_count.values), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50999, 184)\n",
      "(51000, 184)\n"
     ]
    }
   ],
   "source": [
    "# assemble features\n",
    "\n",
    "tmp = pd.concat([feat_raw, feat_count], axis=1)\n",
    "train_c = tmp[train_set==1]\n",
    "test_c = tmp[train_set==0]\n",
    "\n",
    "print(train_c.shape)\n",
    "print(test_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------- Modeling -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0.344305706189\n",
      "CPU times: user 25.2 s, sys: 996 ms, total: 26.2 s\n",
      "Wall time: 45.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from wrappers import VWRegressor\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# namespaces = {'A': [x for x in train_c.columns if x.startswith('T1')],\n",
    "#               'B': [x for x in train_c.columns if x.startswith('T2')]}\n",
    "\n",
    "# namespaces = {'A': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes) \n",
    "#                         if col.startswith('T') and dtype=='object'],\n",
    "#               'B': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes) \n",
    "#                         if col.startswith('T') and dtype!='object'],\n",
    "#               'C': [col for col in train_c.columns if col.startswith('count')]}\n",
    "\n",
    "namespaces = {'A': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes) \n",
    "                        if col.startswith('T') and dtype=='object'],\n",
    "              'B': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes)\n",
    "                        if col.startswith('T') and dtype!='object']}\n",
    "\n",
    "\n",
    "scores = []\n",
    "vw = VWRegressor(passes=10, l2=1E-6, l1=1E-6, bit=20, interaction='AB', namespaces=namespaces)\n",
    "for i, (idx_train, idx_test) in enumerate(KFold(train.shape[0], 10)):\n",
    "    print(i)\n",
    "    vw.fit(train_c.ix[idx_train, :], train.Hazard[idx_train])\n",
    "    pred = vw.predict(train_c.ix[idx_test, :])\n",
    "    scores.append(gini.normalized_gini(train.Hazard[idx_test], pred))\n",
    "    \n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wrappers import VWRegressor\n",
    "\n",
    "namespaces = {'A': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes) \n",
    "                        if col.startswith('T') and dtype=='object'],\n",
    "              'B': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes) \n",
    "                        if col.startswith('T') and dtype!='object'],\n",
    "              'C': [col for col in train_c.columns if col.startswith('count')]}\n",
    "\n",
    "# namespaces = {'A': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes) \n",
    "#                         if col.startswith('T') and dtype=='object'],\n",
    "#               'B': [col for col, dtype in zip(train_c.columns, train_c[train_c.columns].dtypes)\n",
    "#                         if col.startswith('T') and dtype!='object']}\n",
    "\n",
    "vw = VWRegressor(passes=20, l2=1E-6, l1=1E-6, bit=20, interaction='AB', namespaces=namespaces)\n",
    "vw.fit(train_c, train.Hazard)\n",
    "yhat = vw.predict(test_c)\n",
    "pd.DataFrame({'Id': test.Id, 'Hazard': yhat}).reindex_axis(['Id', 'Hazard'], 1).to_csv('../output/linear_v2_05.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': test.Id, 'Hazard': yhat}).reindex_axis(['Id', 'Hazard'], 1).to_csv('../output/linear_v2_05.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.330865678696\n",
      "CPU times: user 15min 54s, sys: 636 ms, total: 15min 55s\n",
      "Wall time: 15min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albertium/anaconda3/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:444: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "model = ElasticNet(alpha=1E-3, l1_ratio=0.5, max_iter=2000)\n",
    "scores = []\n",
    "time = 1\n",
    "for idx_train, idx_test in KFold(train.shape[0], 5):\n",
    "    print(time)\n",
    "    time += 1    \n",
    "    model.fit(train_c.ix[idx_train, :], train.Hazard[idx_train])\n",
    "    pred = model.predict(train_c.ix[idx_test, :])\n",
    "    scores.append(gini.normalized_gini(train.Hazard[idx_test], pred))\n",
    "\n",
    "print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
